mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(ran, ip_id, package, country)
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran,country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux=gnu")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id
)
arrange(cran2, country, desc(r_version), ip_Id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
install.packages("twitteR")
library(twitteR)
favorites(In(Social)MediasRes)
favorites("In(Social)MediasRes")
registerTwitterOAuth
favorites("In(Social)MediasRes")
?setup_twitter_oauth
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc<- htmlTreeParse(fileUrl, useInternal = TRUE)
library(XML)
doc<- htmlTreeParse(fileUrl, useInternal = TRUE)
scores <- xpathSapply(doc, "//li[@class='score']",xmlValue)
scores <- xpathSApply(doc, "//li[@class='score']",xmlValue)
teams <- xpathSApply(doc, "//li[@class='team-name']",xmlValue)
teams
scores
scores[[1]]
scores <- xpathSApply(doc, "//li[@class='score']", xmlValue)
View(doc)
scores <- xmlSApply(doc, "//li[@class='score']", xmlValue)
fileUrl <- "http://espn.go.com/nfl/team/schedule/_/name/bal/year/2014"
doc<- htmlTreeParse(fileUrl, useInternal = TRUE)
scores <- xpathSApply(doc, "//li[@class='score']", xmlValue)
teams <- xpathSApply(doc, "//li[@class='team-name']",xmlValue)
scores
teams
rm(list = ls())
library(jsonlite)
jsonData<-fromJSON("https://api/github.com/users/jtleek/repos")
jsonData<-fromJSON("https://api.github.com/users/jtleek/repos")
names(jsonData)
install.packages("RMySQL")
library(RMySQL)
rm("jsonData")
ucscDB<- dbcConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
ucscDB<- dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
result<-dbGetQuery(ucscDB, "showdatabases;"); dbDisconnect(ucscDb)
result<-dbGetQuery(ucscDB, "show databases;"); dbDisconnect(ucscDb)
result<-dbGetQuery(ucscDB, "show databases;"); dbDisconnect(ucscDB)
result
hg19<-dbConnect(MySQL(), user = "genome", db = "hg19", host = "genome-mysql.cse.ucsc.edu")
allTables<-dbListTables(hg19)
length(allTables)
allTables[1:5]
dbListFields(hg19, "affyU133Plus2")
library(rhdf5)
created = h5createfile("example.h5")
created = h5createFile("example.h5")
created
created = h5createGroup("example.h5", "foo")
created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
A = matrix(1:10, nr=5, nc=2)
a
A
h5write(A, "example.h5", "foo/A")
B = array(seq(.1,2,by=.1),dim=c(5,2,2))
B
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5L, seq(0,1,length.out=5),c("ab","cde","fghi","a","s"), stringsAsFactors = FALSE)
df
h5write(df, "example.h5", "df")
hfls("example.h5")
h5ls("example.h5")
readA = h5read("example.h5", "foo/A")
readB = h5read("example.h5", "foo/foobaa/A")
readB = h5read("example.h5", "foo/foobaa/B")
readA
readB
readdf = h5read("example.h5", "df")
readdf
rm(list = ls())
con = url("htp://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ&hl=en")
htmlCode = readlines(con)
htmlCode = readLines(con)
htmlCode
rm(list=ls())
library)httr
library(httr)
myapp = oauth_app("twitter", key="5VRlqhvtJLSpqzeNdFm5ew0Ft", secret="5MqJnPYJ87DgmdSGzB63Ji38nlqNKz8putkkLKt8WdxMQbhaA4")
sig = sign_oauth1.0(myapp, token = "223348930-OAIXpkLAMXHa8FHMZv6cEB23Y8XqhGRaUfJF82wV", token_secret = "7jdfhPBLbAjmtMtrXGU7YikB6YWKVVaCRRylfwn6C7tkn")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
head(homeTL)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
library(jsonlite)
json2 = jsonlite::fromJSON(toJSON(json1))
json2(1,1:4)
json2[1,1:4]
library(httr)
myapp = oauth_app("twitter", key="5VRlqhvtJLSpqzeNdFm5ew0Ft", secret="5MqJnPYJ87DgmdSGzB63Ji38nlqNKz8putkkLKt8WdxMQbhaA4")
sig = sign_oauth1.0(myapp, token = "223348930-OAIXpkLAMXHa8FHMZv6cEB23Y8XqhGRaUfJF82wV", token_secret = "7jdfhPBLbAjmtMtrXGU7YikB6YWKVVaCRRylfwn6C7tkn")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
json1 = content(homeTL)
library(jsonlite)
json2 = jsonlite::fromJSON(toJSON(json1))
names(jason2)
names(json2)
names(json2[1])
names(json2[[1]])
json2
json[1]
json2[1]
json2[[1]]
library(Shiney)
library(Shiny)
library(shiny)
runExample("01_hello")
runExample("02_hello")
runExample("02_text")
library(swirl)
swirl()
install_from_swirl("Statistical Inference")
swirl()
1-((2+1)/36)
deck
52
52/4
13
4/52
0
12
12/52
2/51
library(swirl)
swirl()
swirl()
swirl()
.8
1.6*.8/2
.64
mypdf
?int
integrate(mypdf, 0, 1.6)
.8
sqrt(2)
.997*.001
.03*.999
.003*.999
1.5*.999
.015*.999
.000997*/(.000997+.014985)
.000997/(.000997+.014985)
(1+2+3+4+5+60/6
(1+2+3+4+5+6)/6
expect_dice
dice_high
expect_dice(dice_high)
expect_dice(dice_low)
.5*edh*edl
.5*(edh+edl)
integrate(myfunc,0,2)
spop
mean(spop)
allsam
apply(allsam, 1, mean)
mean(smeans)
install.packages("kernlab")
data(spam)
library(kernlab)
data(spam)
str(spam[, 1:5])
trainIndicator = rbinom(4601, size = 1, prob = .5)
table(trainIndicator)
trainSpam = spam[trainIndicator == 1 ,]
testSpam = spam[trainIndicator == 0,]
str(trainSpam)
names(trainSpam)
head(trainSpam)
table(trainSpam$type)
log10(0)
plot(trainSpam$capitalAve ~ trainSpam$type)
plot(log10(trainSpam$capitalAve + 1) ~ trainSpam$type)
plot(log10(trainSpam[,1:4]+1))
hCluster = hclust(dist(t(trainSpam[,1:57])))
plot(hCluster)
hCluster = hclust(dist(t(log10(trainSpam[,1:57]+1))))
plot(hCluster)
trainSpam$numType = as.numeric(trainSpam$type) - 1
costFunction = function(x,y) sum( x != (y > 0.5))
cvError = rep(NA, 55)
library(boot)
for (i in 1:55){}
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
}
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = flm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, custFunction, 2)$delta[2]
}
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, custFunction, 2)$delta[2]
}
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = flm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
for (i in 1:55){
lmFormula = reformulate(names(trainSpam)[i], response = "numType")
glmFit = glm(lmFormula, family = "binomial", data = trainSpam)
cvError[i] = cv.glm(trainSpam, glmFit, costFunction, 2)$delta[2]
}
names(trainSpam)[which.min(cvError)]
# Use the best model of the group
predictionModel = glm(numType ~ charDollar, family = “binomial”, dta = trainSpam)
# Get predictions using this model on the test data
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep(“nonspam”, dim(testSpam)[1])
# Classify as ‘spam’ for those with prob > 0.5
predictedSpam[predictionModel$fitted > 0.5] = “spam"
predictionModel = glm(numType ~ charDollar, family = “binomial”, dta = trainSpam)
predictionModel = glm(numType ~ charDollar, family = “binomial”, data = trainSpam)
predictionModel = glm(numType ~ charDollar, family = "binomial", data = trainSpam)
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep(“nonspam”, dim(testSpam)[1])
predictionTest = predict(predictionModel, testSpam)
predictedSpam = rep("nonspam", dim(testSpam)[1])
predictedSpam
predictedSpam[predictionModel$fitted > 0.5] = “spam"
predictedSpam[predictionModel$fitted > 0.5] = "spam"
predictedSpam
#Classification table
table(predictSpam, testSpam$type)
#Classification table
table(predictedSpam, testSpam$type)
table(predictedSpam, testSpam$type)
table(predictedSpam, testSpam$type)
?quantile
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
1*.1+2*.2+3*.3+4*.4
library(swirl)
rm(list=ls())
swirl()
dice_sqr
ex2_fair <- sum(dice_sqr * dice_fair)
ex2_fair - 3.5^2
sum(dice_sqr * dice_high) - edh^2
sd(apply(matrix(rnorm(10000),1000),1,mean))
1/sqrt(10)
s/sqrt(120)
1/sqrt(120)
sd(apply(matrix(rnunif(10000),1000),1,mean))
sd(apply(matrix(runif(10000),1000),1,mean))
2/sqrt(10)
sd(apply(matrix(rpois(10000,4),1000),1,mean))
1/(2*sqrt(10))
sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
install.packages("xtable")
?lm
?glm
?lm
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
x %*% w
.18*2-1.54+.42*3+.95
1.03/4
mean(rep(.18, 2), rep(-1.54, 1), rep(.42, 3), .95 )
rep(.18,2)
mean(c(rep(.18, 2), rep(-1.54, 1), rep(.42, 3), .95) )
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef(lm(y~x))
coef(lm(y~0+x))
data(mtcars)
coef(lm(mtcars$mpg ~ mtcars$weight))
names(mtcars)
coef(lm(mtcars$mpg ~ mtcars$wt))
beta1 <- .5* 2
beta0 <- mean(mtcars$mpg) - beta1*mean(mtcars$wt)
beta0
1.5*.4
1.5/.4
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
(8.58 - mean(x))/sd(X)
x
(8.58 - mean(x))/sd(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
coef(lm(y~x))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
x
x-.573
sum(x-.573)
lm(x~x)
library(kernlab)
data(spam)
name(spam)
names(spam)
str(spam)
quartz()
plot(densit(spam$your[spam$tpye == "nonspam"])), col = "blue", main = "", xlab " Freq of yours")
plot(density(spam$your[spam$tpye == "nonspam"])), col = "blue", main = "", xlab " Freq of yours")
plot(density(spam$your[spam$tpye == "nonspam"]), col = "blue", main = "", xlab " Freq of yours")
plot(density(spam$your[spam$tpye == "nonspam"]), col = "blue", main = "", xlab = " Freq of yours")
plot(density(spam$your[spam$ttype == "nonspam"]), col = "blue", main = "", xlab = " Freq of yours")
plot(density(spam$your[spam$type == "nonspam"]), col = "blue", main = "", xlab = " Freq of yours")
lines(density(spam$your[spam$type == "spam"]), col="red")
abline(v = .5, col = "black")
prediction <- ifelse(spam$your > 0.5, "spam", "nonspam")
table(prediction, spam$type)/length(spam$type)
x <- 100
x = rnorm(n)
n <- 100
x = rnorm(n)
x2 = rnorm(n)
x3 = rnorm(n)
y = 1 + 2 +x2 + x3 + rnorm(d, sd = .1)
y = 1 + 2 +x2 + x3 + rnorm(n, sd = .1)
ey <- resid(lm(y ~ x2 + x3))
ex <- resid(lm(x ~ x2 + x3))
sum(ey *ex) / sum(ex^2)
coef(lm(y~ x + x2 + x3))
coef(lm(ey ~ ex - 1))
clear(list = ls())
rm(list = ls())
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
fit
summary(fit)
coef(fit[4,2])
coef(fit[2,4])
coef(fit)
summary(fit)
data(mtcars)
names(mtcars)
fit <- lm(mpg ~ wt)
fit <- lm(mpg ~ wt, data = mtcars)
fit
summary(fit)
sumCoef <- summary(fit)$coefficients
sumCoef
fit$df
predict(fit, newdata = mean(mtcars$wt))
?predict
newdata = data.frame(wt = mean(mtcars$wt))
predict(fit, newdata, interval="predict")
mean(mtcars$wt)
fit
newdata
predict(fit, newdata)
predict(fit, newdata, interval = "predict")
newwt = data.frame(wt = mean(mtcars$wt))
predict(fit, newdata = newwt, interval = "predict")
predict(fit, newdata = newwt, interval = ("predict"))
predict(fit, newdata = newwt, interval = ("confidence"))
?mtcars
predict(fit, newdata = data.frame(wt = 3), interval = ("predict"))
fit <- lm(mpg ~ wt /2, data = mtcars)
fit <- lm(mpg ~ I(wt /2), data = mtcars)
summary(fit)
fit2 <- lm(mpg ~ I(wt - mean(wt)), data = mtcars)
summary(fit2)
-10.689 - 1.118*2
len(mtcars$wt)
length(mtcars$wt)
length(unique(mtcars$wt))
z <- rnorm(100)
sample(z, 50)
?sample
library(swirl)
swirl()
all <- lm(Fertility ~ ., data = "swiss")
all <- lm(Fertility ~ ., data = swiss)
summary(all)
summary(lm(Fertility ~ agriculture, data = swiss))
summary(lm(Fertility ~ Agriculture, data = swiss))
cor(swiss$Examination, swiss$Education)
cor(swiss$Agriculture, swiss$Education)
makelms()
ec -> sum(swiss$Examination, swiss$Catholic)
ec <- sum(swiss$Examination, swiss$Catholic)
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility ~. + ec, swiss)
coefs(all) - coefs(Efit)
coef(all) - coef(efit)
all$coefficients-efit$coefficients
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
library(caret)
rfmod <- train(y ~ ., data = voew.train, method = 'rf')
rfmod <- train(y ~ ., data = vowel.train, method = 'rf')
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
# fit rf predictor relating the factor variable y
fitRf <- train(y ~ ., data=vowel.train, method="rf")
fitGBM <- train(y ~ ., data=vowel.train, method="gbm")
predRf <- predict(fitRf, vowel.test)
predGBM <- predict(fitGBM, vowel.test)
# RF Accuracy: 0.6060606
confusionMatrix(predRf, vowel.test$y)$overall[1]
# GBM Accuracy: 0.530303
confusionMatrix(predGBM, vowel.test$y)$overall[1]
pred <- data.frame(predRf, predGBM, y=vowel.test$y, agree=predRf == predGBM)
head(pred)
accuracy <- sum(predRf[pred$agree] == pred$y[pred$agree]) / sum(pred$agree)
accuracy # Agreement Accuracy: 0.6569579
library(dplyr)
library(pander)
data(mtcars)
mtcars <- tbl_df(mtcars)
cars <- mtcars %>%
select(mpg, am) %>%  #
mutate( Trans = ifelse(am==0, "Automatic", "Manual")) %>%
group_by(Trans)
tab <- summarise(cars, N = n(), Mean = mean(mpg), Med = median(mpg), sd = sd(mpg))
base.fit <- lm(mpg ~ am, mtcars)
summary(base.fit)$coefficients
base.fit
base.fit$coefficients
summary(base.git)
summary(base.fit)
?step
fullmodel <- lm(mpg ~ . , data = mtcars)
summary(fullmodel)$coefficients
stepmodel <- step(fullmodel, direction = "backward")
shiny::runApp('datasciencecoursera/Data Products/Project/Coursera-Data-Products')
shiny::runApp('datasciencecoursera/Data Products/Project/Coursera-Data-Products')
setwd("~/datasciencecoursera/Data Products/Project/Coursera-Data-Products")
library(shinyapps)
deployApp()
setwd("~/datasciencecoursera/Machine Learning/Exercise ID Project/Coursera-Machine-Learning")
library(caret)
library(dplyr)
set.seed(311)
NAs <- c("", "#DIV/0!", "NA")
pml <- read.csv("pml-training.csv", na.strings = NAs)
fin <- apply(apply(pml, 2, is.na), 2, sum) # Count number of NAs in each column
good.vars.names <- names(fin[fin<10000]) # Make a vector of good column names, used to subet
pml.df <- tbl_df(pml)
pml.pruned <- select(pml.df, one_of(good.vars.names)) %>% select(-(1:7))
train.index <- createDataPartition(y = pml.pruned$classe, p = 0.7, list = FALSE)
pml.train <- pml.pruned[train.index,]
pml.test <- pml.pruned[-train.index,]
fitControl <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 1)
mod1 <- train(classe ~ ., data = pml.train, method = 'rf', trControl = fitControl)
pm.test.preds <- predict(mod1, pml.test)
confusionMatrix(pm.test.preds, pml.test$classe)
save.image("~/datasciencecoursera/Machine Learning/Exercise ID Project/Coursera-Machine-Learning/MLmodelproj.RData")
mod1$finalModel ; confusionMatrix(mod1)
pm.test.preds <- predict(mod1, newdata = pml.test)
confusionMatrix(pm.test.preds, pml.test$classe)
setwd("~/datasciencecoursera/Machine Learning/Exercise ID Project/Coursera-Machine-Learning")
setwd("~/datasciencecoursera/Machine Learning/Exercise ID Project/Coursera-Machine-Learning")
+RTS -Ksize -RTS
+RTS
